# Определение весо-габаритных характеристик товаров
> **Репозиторий ДЗ по PromDaFall2025**

---

## О проекте

В качестве ML проекта я взял задачу, которую делал на работе. А именно **определение веса и габаритов (Индивидуальных Весо-Габаритных Характеристик)** товаров из объявлений на Авито для дальнейшего определения стоимости доставки.

### Небольшой дисклеймер

> Чтобы избежать проблем с NDA и прочим, здесь используется небольшой слепок данных:
> - Очищенный от ПД
> - Без внутренних ID
> - С зашумленным таргетом
> - С неполным набором фичей для обучения
>
> Это плохо повлияет на перфоманс модели, но это не суть ДЗ, так что не судите строго.

---

## Немного контекста

В Авито после публикации объявления рассчитывается стоимость доставки. Ранее она рассчитывалась исходя из категорийных ИВГХ, которые подбирались вручную людьми (на каждую доставочную категорию).

Эти КВГХ были завышены относительно средних ВГХ по микрокатегориям, чтобы компания не уходила в огромный минус за доставку.

Решение: создание интерпретируемой и не сильно тяжеловесной ML-модели для определения ИВГХ на каждый товар в отдельности.

---

## Архитектура решения

### Модели
Используются **2 CatBoost модели**:
1. **Модель веса** - регрессия веса (в кг)
2. **Модель габаритов** - мульти-регрессия (высота, длина, ширина в см)

### Фичи для модели веса
```python
[
    'title',           # заголовок объявления
    'description',     # описание объявления
    'price',           # цена из объявления
    'mean_weight',     # средний вес по микрокатегории
    'std_weight'       # стандартное отклонение веса в микрокатегории
]
```


Для модели габаритов все аналогично, только добавляются статистики по всем 3 габаритам.

> На практике оказалось, что лучше всего модели делать независимыми (обучать вес отдельно от габаритов, и выходы 1 модели не передавать во 2)

---

## Работа с микрокатегориями

В датасетах есть `microcat_id` - это просто заэнкоженные микрокатегории, число в диапазоне от 0-318.

> **Важно:** модель не может работать с неизвестными микрокатами и будет падать! Есть ручка для проверки микроката и получения его названия

Также есть файл `microcat.json` со статистиками по микрокатам Добавление статистик из json считается предобработкой данных. По хорошему было занести json в горячее хранилище (Redis), но пока руки не дошли...

---

## Быстрый старт

### Запуск сервиса

```bash
# Вариант 1 - используя make
make start_service

# Вариант 2 - напрямую через docker-compose
docker-compose up --build -d
```

Стоит куча health-чеков, возможно нужно подождать или поменять параметры ожидания в health-чеках.


### Доступные интерфейсы

| Сервис | URL | Описание |
|--------|-----|----------|
| **API & Swagger** | [http://localhost:8000/docs](http://localhost:8000/docs) | Бекенд API и пока по совместительству фронтенд |
| **MLflow** | [http://localhost:5000](http://localhost:5000) | Трекинг экспериментов |
| **Grafana** | [http://localhost:3000/d/adlsq8n/monitoring-dashboard](http://localhost:3000/d/adlsq8n/monitoring-dashboard) | Мониторинг и дашборды |
| **Prometheus** | [http://localhost:9090](http://localhost:9090) | Метрики |

---

## Возможности сервиса

- **По умолчанию** загружаются модели из локального файла
- Можно **загрузить в cold_feature_store** данные из CSV / Parquet
- **Запустить обучение** через ручку `/retrain` или через CLI
- **Просмотр метрик** и **деплой моделей**
